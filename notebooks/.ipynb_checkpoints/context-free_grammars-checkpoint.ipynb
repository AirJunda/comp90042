{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context-Free Grammars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NTLK has a module for building context-free grammars from a string representation of the rules. Let's start by creating our toy grammar from the lecture, and generating the four possible sentences that can be derived using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'the', u'rat', u'ate', u'the', u'rat']\n",
      "[u'the', u'rat', u'ate', u'the', u'cheese']\n",
      "[u'the', u'cheese', u'ate', u'the', u'rat']\n",
      "[u'the', u'cheese', u'ate', u'the', u'cheese']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.parse.generate import generate\n",
    "toy_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "  S -> NP VP\n",
    "  VP -> VBG NP \n",
    "  VBG -> \"ate\"\n",
    "  NP -> DT NN\n",
    "  DT -> \"the\"\n",
    "  NN -> \"rat\" | \"cheese\" \n",
    "  \"\"\")\n",
    "\n",
    "for sentence in generate(toy_grammar):\n",
    "    print sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's examine our grammar a bit. We can iterate through the rules (productions), look at the symbols on their left hand and right hand sides, and see whether they're terminals or non-terminals. We'll do this to create a list of terminals and non-terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S -> NP VP\n",
      "S\n",
      "(NP, VP)\n",
      "VP -> VBG NP\n",
      "VP\n",
      "(VBG, NP)\n",
      "VBG -> 'ate'\n",
      "VBG\n",
      "(u'ate',)\n",
      "NP -> DT NN\n",
      "NP\n",
      "(DT, NN)\n",
      "DT -> 'the'\n",
      "DT\n",
      "(u'the',)\n",
      "NN -> 'rat'\n",
      "NN\n",
      "(u'rat',)\n",
      "NN -> 'cheese'\n",
      "NN\n",
      "(u'cheese',)\n",
      "terminals\n",
      "set([u'cheese', u'the', u'ate', u'rat'])\n",
      "nonterminals\n",
      "set([NP, VP, DT, VBG, NN])\n"
     ]
    }
   ],
   "source": [
    "terminals = set()\n",
    "nonterminals = set()\n",
    "for production in toy_grammar.productions():\n",
    "    print production\n",
    "    print production.lhs()\n",
    "    print production.rhs()\n",
    "    for symbol in production.rhs():\n",
    "        if nltk.grammar.is_terminal(symbol):\n",
    "            terminals.add(symbol)\n",
    "        else:\n",
    "            nonterminals.add(symbol)\n",
    "\n",
    "print \"terminals\"\n",
    "print terminals\n",
    "print \"nonterminals\"\n",
    "print nonterminals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use Early parsing to parse a sentence using our grammar. NLTK has a built-in version of the algorithm that you can use. We can set trace=2 to show the steps that the model is taking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.  the  .  rat  .  ate  .  the  . cheese.|\n",
      "Leaf Init Rule:\n",
      "|[-------]       .       .       .       .| [0:1] 'the'\n",
      "|.       [-------]       .       .       .| [1:2] 'rat'\n",
      "|.       .       [-------]       .       .| [2:3] 'ate'\n",
      "|.       .       .       [-------]       .| [3:4] 'the'\n",
      "|.       .       .       .       [-------]| [4:5] 'cheese'\n",
      "Top Down Init Rule:\n",
      "|>       .       .       .       .       .| [0:0] S  -> * NP VP\n",
      "\n",
      "* Processing queue: 0 \n",
      "\n",
      "Predictor Rule:\n",
      "|>       .       .       .       .       .| [0:0] NP -> * DT NN\n",
      "Predictor Rule:\n",
      "|>       .       .       .       .       .| [0:0] DT -> * 'the'\n",
      "\n",
      "* Processing queue: 1 \n",
      "\n",
      "Scanner Rule:\n",
      "|[-------]       .       .       .       .| [0:1] DT -> 'the' *\n",
      "Completer Rule:\n",
      "|[------->       .       .       .       .| [0:1] NP -> DT * NN\n",
      "Predictor Rule:\n",
      "|.       >       .       .       .       .| [1:1] NN -> * 'rat'\n",
      "\n",
      "* Processing queue: 2 \n",
      "\n",
      "Scanner Rule:\n",
      "|.       [-------]       .       .       .| [1:2] NN -> 'rat' *\n",
      "Completer Rule:\n",
      "|[---------------]       .       .       .| [0:2] NP -> DT NN *\n",
      "Completer Rule:\n",
      "|[--------------->       .       .       .| [0:2] S  -> NP * VP\n",
      "Predictor Rule:\n",
      "|.       .       >       .       .       .| [2:2] VP -> * VBG NP\n",
      "Predictor Rule:\n",
      "|.       .       >       .       .       .| [2:2] VBG -> * 'ate'\n",
      "\n",
      "* Processing queue: 3 \n",
      "\n",
      "Scanner Rule:\n",
      "|.       .       [-------]       .       .| [2:3] VBG -> 'ate' *\n",
      "Completer Rule:\n",
      "|.       .       [------->       .       .| [2:3] VP -> VBG * NP\n",
      "Predictor Rule:\n",
      "|.       .       .       >       .       .| [3:3] NP -> * DT NN\n",
      "Predictor Rule:\n",
      "|.       .       .       >       .       .| [3:3] DT -> * 'the'\n",
      "\n",
      "* Processing queue: 4 \n",
      "\n",
      "Scanner Rule:\n",
      "|.       .       .       [-------]       .| [3:4] DT -> 'the' *\n",
      "Completer Rule:\n",
      "|.       .       .       [------->       .| [3:4] NP -> DT * NN\n",
      "Predictor Rule:\n",
      "|.       .       .       .       >       .| [4:4] NN -> * 'cheese'\n",
      "\n",
      "* Processing queue: 5 \n",
      "\n",
      "Scanner Rule:\n",
      "|.       .       .       .       [-------]| [4:5] NN -> 'cheese' *\n",
      "Completer Rule:\n",
      "|.       .       .       [---------------]| [3:5] NP -> DT NN *\n",
      "Completer Rule:\n",
      "|.       .       [-----------------------]| [2:5] VP -> VBG NP *\n",
      "Completer Rule:\n",
      "|[=======================================]| [0:5] S  -> NP VP *\n",
      "(S (NP (DT the) (NN rat)) (VP (VBG ate) (NP (DT the) (NN cheese))))\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.parse.EarleyChartParser(toy_grammar, trace=2)\n",
    "for parse in parser.parse(\"the rat ate the cheese\".split()):\n",
    "    print parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are exactly the same steps as we saw in lecture, except this version has the prediction of lexical rules such as NN -> 'cheese' in the step before scanning them. You should look through these steps again to make sure you understand them.\n",
    "\n",
    "Let's try to go beyond our toy grammar. Building one by hand would be painful, but fortunately NLTK contains a portion of the human-annotated Penn Treebank, which we can use for grammar induction. First, though, let's take a look at some trees from the Penn Treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP-SBJ\n",
      "    (NP (NNP Pierre) (NNP Vinken))\n",
      "    (, ,)\n",
      "    (ADJP (NP (CD 61) (NNS years)) (JJ old))\n",
      "    (, ,))\n",
      "  (VP\n",
      "    (MD will)\n",
      "    (VP\n",
      "      (VB join)\n",
      "      (NP (DT the) (NN board))\n",
      "      (PP-CLR (IN as) (NP (DT a) (JJ nonexecutive) (NN director)))\n",
      "      (NP-TMP (NNP Nov.) (CD 29))))\n",
      "  (. .))\n",
      "(S\n",
      "  (NP-SBJ (NNP Mr.) (NNP Vinken))\n",
      "  (VP\n",
      "    (VBZ is)\n",
      "    (NP-PRD\n",
      "      (NP (NN chairman))\n",
      "      (PP\n",
      "        (IN of)\n",
      "        (NP\n",
      "          (NP (NNP Elsevier) (NNP N.V.))\n",
      "          (, ,)\n",
      "          (NP (DT the) (NNP Dutch) (VBG publishing) (NN group))))))\n",
      "  (. .))\n",
      "(S\n",
      "  (NP-SBJ-1\n",
      "    (NP (NNP Rudolph) (NNP Agnew))\n",
      "    (, ,)\n",
      "    (UCP\n",
      "      (ADJP (NP (CD 55) (NNS years)) (JJ old))\n",
      "      (CC and)\n",
      "      (NP\n",
      "        (NP (JJ former) (NN chairman))\n",
      "        (PP\n",
      "          (IN of)\n",
      "          (NP (NNP Consolidated) (NNP Gold) (NNP Fields) (NNP PLC)))))\n",
      "    (, ,))\n",
      "  (VP\n",
      "    (VBD was)\n",
      "    (VP\n",
      "      (VBN named)\n",
      "      (S\n",
      "        (NP-SBJ (-NONE- *-1))\n",
      "        (NP-PRD\n",
      "          (NP (DT a) (JJ nonexecutive) (NN director))\n",
      "          (PP\n",
      "            (IN of)\n",
      "            (NP\n",
      "              (DT this)\n",
      "              (JJ British)\n",
      "              (JJ industrial)\n",
      "              (NN conglomerate)))))))\n",
      "  (. .))\n",
      "(S\n",
      "  (S-TPC-1\n",
      "    (NP-SBJ\n",
      "      (NP (NP (DT A) (NN form)) (PP (IN of) (NP (NN asbestos))))\n",
      "      (RRC\n",
      "        (ADVP-TMP (RB once))\n",
      "        (VP\n",
      "          (VBN used)\n",
      "          (NP (-NONE- *))\n",
      "          (S-CLR\n",
      "            (NP-SBJ (-NONE- *))\n",
      "            (VP\n",
      "              (TO to)\n",
      "              (VP\n",
      "                (VB make)\n",
      "                (NP (NNP Kent) (NN cigarette) (NNS filters))))))))\n",
      "    (VP\n",
      "      (VBZ has)\n",
      "      (VP\n",
      "        (VBN caused)\n",
      "        (NP\n",
      "          (NP (DT a) (JJ high) (NN percentage))\n",
      "          (PP (IN of) (NP (NN cancer) (NNS deaths)))\n",
      "          (PP-LOC\n",
      "            (IN among)\n",
      "            (NP\n",
      "              (NP (DT a) (NN group))\n",
      "              (PP\n",
      "                (IN of)\n",
      "                (NP\n",
      "                  (NP (NNS workers))\n",
      "                  (RRC\n",
      "                    (VP\n",
      "                      (VBN exposed)\n",
      "                      (NP (-NONE- *))\n",
      "                      (PP-CLR (TO to) (NP (PRP it)))\n",
      "                      (ADVP-TMP\n",
      "                        (NP\n",
      "                          (QP (RBR more) (IN than) (CD 30))\n",
      "                          (NNS years))\n",
      "                        (IN ago))))))))))))\n",
      "  (, ,)\n",
      "  (NP-SBJ (NNS researchers))\n",
      "  (VP (VBD reported) (SBAR (-NONE- 0) (S (-NONE- *T*-1))))\n",
      "  (. .))\n",
      "(S\n",
      "  (S-TPC-2\n",
      "    (NP-SBJ\n",
      "      (NP (DT The) (NN asbestos) (NN fiber))\n",
      "      (, ,)\n",
      "      (NP (NN crocidolite))\n",
      "      (, ,))\n",
      "    (VP\n",
      "      (VBZ is)\n",
      "      (ADJP-PRD (RB unusually) (JJ resilient))\n",
      "      (SBAR-TMP\n",
      "        (IN once)\n",
      "        (S\n",
      "          (NP-SBJ (PRP it))\n",
      "          (VP (VBZ enters) (NP (DT the) (NNS lungs)))))\n",
      "      (, ,)\n",
      "      (PP\n",
      "        (IN with)\n",
      "        (S-NOM\n",
      "          (NP-SBJ\n",
      "            (NP (RB even) (JJ brief) (NNS exposures))\n",
      "            (PP (TO to) (NP (PRP it))))\n",
      "          (VP\n",
      "            (VBG causing)\n",
      "            (NP\n",
      "              (NP (NNS symptoms))\n",
      "              (SBAR\n",
      "                (WHNP-1 (WDT that))\n",
      "                (S\n",
      "                  (NP-SBJ (-NONE- *T*-1))\n",
      "                  (VP\n",
      "                    (VBP show)\n",
      "                    (PRT (RP up))\n",
      "                    (ADVP-TMP (NP (NNS decades)) (JJ later)))))))))))\n",
      "  (, ,)\n",
      "  (NP-SBJ (NNS researchers))\n",
      "  (VP (VBD said) (SBAR (-NONE- 0) (S (-NONE- *T*-2))))\n",
      "  (. .))\n"
     ]
    }
   ],
   "source": [
    "for tree in nltk.corpus.treebank.parsed_sents()[0:5]:\n",
    "      print tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem with the default Penn Treebank annotation is that some of its nonterminals include sentential grammatical role labels which don't make sense for building a CFG grammar (for instance, NP-SBJ for NPs as the subject as the sentence). Let's write a function to remove them. To do this, we'll have to traverse these trees, and change the labels on the nodes. This is fairly easy, since iterating over a NLTK tree with a for loop means to interate over its children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP\n",
      "    (NP (NNP Pierre) (NNP Vinken))\n",
      "    (, ,)\n",
      "    (ADJP (NP (CD 61) (NNS years)) (JJ old))\n",
      "    (, ,))\n",
      "  (VP\n",
      "    (MD will)\n",
      "    (VP\n",
      "      (VB join)\n",
      "      (NP (DT the) (NN board))\n",
      "      (PP (IN as) (NP (DT a) (JJ nonexecutive) (NN director)))\n",
      "      (NP (NNP Nov.) (CD 29))))\n",
      "  (. .))\n",
      "(S\n",
      "  (NP (NNP Mr.) (NNP Vinken))\n",
      "  (VP\n",
      "    (VBZ is)\n",
      "    (NP\n",
      "      (NP (NN chairman))\n",
      "      (PP\n",
      "        (IN of)\n",
      "        (NP\n",
      "          (NP (NNP Elsevier) (NNP N.V.))\n",
      "          (, ,)\n",
      "          (NP (DT the) (NNP Dutch) (VBG publishing) (NN group))))))\n",
      "  (. .))\n",
      "(S\n",
      "  (NP\n",
      "    (NP (NNP Rudolph) (NNP Agnew))\n",
      "    (, ,)\n",
      "    (UCP\n",
      "      (ADJP (NP (CD 55) (NNS years)) (JJ old))\n",
      "      (CC and)\n",
      "      (NP\n",
      "        (NP (JJ former) (NN chairman))\n",
      "        (PP\n",
      "          (IN of)\n",
      "          (NP (NNP Consolidated) (NNP Gold) (NNP Fields) (NNP PLC)))))\n",
      "    (, ,))\n",
      "  (VP\n",
      "    (VBD was)\n",
      "    (VP\n",
      "      (VBN named)\n",
      "      (S\n",
      "        (NP ( *-1))\n",
      "        (NP\n",
      "          (NP (DT a) (JJ nonexecutive) (NN director))\n",
      "          (PP\n",
      "            (IN of)\n",
      "            (NP\n",
      "              (DT this)\n",
      "              (JJ British)\n",
      "              (JJ industrial)\n",
      "              (NN conglomerate)))))))\n",
      "  (. .))\n",
      "(S\n",
      "  (S\n",
      "    (NP\n",
      "      (NP (NP (DT A) (NN form)) (PP (IN of) (NP (NN asbestos))))\n",
      "      (RRC\n",
      "        (ADVP (RB once))\n",
      "        (VP\n",
      "          (VBN used)\n",
      "          (NP ( *))\n",
      "          (S\n",
      "            (NP ( *))\n",
      "            (VP\n",
      "              (TO to)\n",
      "              (VP\n",
      "                (VB make)\n",
      "                (NP (NNP Kent) (NN cigarette) (NNS filters))))))))\n",
      "    (VP\n",
      "      (VBZ has)\n",
      "      (VP\n",
      "        (VBN caused)\n",
      "        (NP\n",
      "          (NP (DT a) (JJ high) (NN percentage))\n",
      "          (PP (IN of) (NP (NN cancer) (NNS deaths)))\n",
      "          (PP\n",
      "            (IN among)\n",
      "            (NP\n",
      "              (NP (DT a) (NN group))\n",
      "              (PP\n",
      "                (IN of)\n",
      "                (NP\n",
      "                  (NP (NNS workers))\n",
      "                  (RRC\n",
      "                    (VP\n",
      "                      (VBN exposed)\n",
      "                      (NP ( *))\n",
      "                      (PP (TO to) (NP (PRP it)))\n",
      "                      (ADVP\n",
      "                        (NP\n",
      "                          (QP (RBR more) (IN than) (CD 30))\n",
      "                          (NNS years))\n",
      "                        (IN ago))))))))))))\n",
      "  (, ,)\n",
      "  (NP (NNS researchers))\n",
      "  (VP (VBD reported) (SBAR ( 0) (S ( *T*-1))))\n",
      "  (. .))\n",
      "(S\n",
      "  (S\n",
      "    (NP\n",
      "      (NP (DT The) (NN asbestos) (NN fiber))\n",
      "      (, ,)\n",
      "      (NP (NN crocidolite))\n",
      "      (, ,))\n",
      "    (VP\n",
      "      (VBZ is)\n",
      "      (ADJP (RB unusually) (JJ resilient))\n",
      "      (SBAR\n",
      "        (IN once)\n",
      "        (S (NP (PRP it)) (VP (VBZ enters) (NP (DT the) (NNS lungs)))))\n",
      "      (, ,)\n",
      "      (PP\n",
      "        (IN with)\n",
      "        (S\n",
      "          (NP\n",
      "            (NP (RB even) (JJ brief) (NNS exposures))\n",
      "            (PP (TO to) (NP (PRP it))))\n",
      "          (VP\n",
      "            (VBG causing)\n",
      "            (NP\n",
      "              (NP (NNS symptoms))\n",
      "              (SBAR\n",
      "                (WHNP (WDT that))\n",
      "                (S\n",
      "                  (NP ( *T*-1))\n",
      "                  (VP\n",
      "                    (VBP show)\n",
      "                    (PRT (RP up))\n",
      "                    (ADVP (NP (NNS decades)) (JJ later)))))))))))\n",
      "  (, ,)\n",
      "  (NP (NNS researchers))\n",
      "  (VP (VBD said) (SBAR ( 0) (S ( *T*-2))))\n",
      "  (. .))\n"
     ]
    }
   ],
   "source": [
    "def remove_grammatical_roles(tree):\n",
    "    try:\n",
    "        if \"-\" in tree.label():\n",
    "            tree.set_label(tree.label().split(\"-\")[0])\n",
    "    except: #we've hit a terminal node\n",
    "        return \n",
    "    for child in tree:\n",
    "        remove_grammatical_roles(child)\n",
    "\n",
    "for tree in nltk.corpus.treebank.parsed_sents()[0:5]:\n",
    "    remove_grammatical_roles(tree)\n",
    "    print tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now let's build a new grammar. NLTK trees have a handy method (productions()) which gives you all the CFG rules for the tree. We can collect these rules across all the texts to build a new CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17616\n"
     ]
    }
   ],
   "source": [
    "from nltk.grammar import CFG,Nonterminal\n",
    "\n",
    "productions = set()\n",
    "\n",
    "for tree in nltk.corpus.treebank.parsed_sents():\n",
    "    remove_grammatical_roles(tree)\n",
    "    for production in tree.productions():\n",
    "        productions.add(production)\n",
    "treebank_grammar = CFG(Nonterminal('S'), list(productions))\n",
    "print len(treebank_grammar.productions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas our old grammar had 7 rules, this one has over 17 thousand. Many of them, however, are the lexical rules which produce terminals nodes. Let's see how many of them are non-lexical by counting only those whose RHS is not a terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3835\n"
     ]
    }
   ],
   "source": [
    "nonlex_count = 0\n",
    "for production in treebank_grammar.productions():\n",
    "    if not nltk.grammar.is_terminal(production.rhs()[0]):\n",
    "        nonlex_count +=1\n",
    "print nonlex_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's still a lot of rules. Let's see if it can parse our original sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Grammar does not cover some of the input words: u\"'rat', 'ate', 'cheese'\".",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c7d6108497a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarleyChartParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtreebank_grammar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mparse\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"the rat ate the cheese\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python27\\lib\\site-packages\\nltk\\parse\\chart.pyc\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, tokens, tree_class)\u001b[0m\n\u001b[0;32m   1348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         \u001b[0mchart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchart_parse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparses\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtree_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python27\\lib\\site-packages\\nltk\\parse\\earleychart.pyc\u001b[0m in \u001b[0;36mchart_parse\u001b[1;34m(self, tokens, trace)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_coverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m         \u001b[0mchart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_chart_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[0mgrammar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python27\\lib\\site-packages\\nltk\\grammar.pyc\u001b[0m in \u001b[0;36mcheck_coverage\u001b[1;34m(self, tokens)\u001b[0m\n\u001b[0;32m    629\u001b[0m             \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m             raise ValueError(\"Grammar does not cover some of the \"\n\u001b[1;32m--> 631\u001b[1;33m                              \"input words: %r.\" % missing)\n\u001b[0m\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_calculate_grammar_forms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Grammar does not cover some of the input words: u\"'rat', 'ate', 'cheese'\"."
     ]
    }
   ],
   "source": [
    "parser = nltk.parse.EarleyChartParser(treebank_grammar, trace=0)\n",
    "for parse in parser.parse(\"the rat ate the cheese\".split()):\n",
    "    print parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, because it was built on Wall Street Journal texts, it doesn't know about rats, cheese, or even eating. Unfortunately, even when the vocabulary of sentence is covered, the grammar is completely unusable (in this context). To demonstrate why, try running the below, though note that it might crash your iPython notebook session. We will switch to a bottom up parser which works a bit better in this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parser = nltk.parse.BottomUpChartParser(treebank_grammar, trace=0)\n",
    "for parse in parser.parse(\"revenue increased last quarter\".split()):\n",
    "    print parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In short, way, way, way too many possible parses, almost all of which are absolute junk. Toy grammars make parsing look easy, but parsing with a large grammar involves huge amounts of ambiguity, you need ways to filter out the junk to find the one true parse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
